<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="robots" content="index, follow">
    <title>Face Dataset Compression using PCA | Rodrigo Soares</title>
    <meta name="keywords" content="ML, AI, Python, PCA, Data Compression">
    <meta name="description" content="Principal Component Analysis for Image Dataset Compression">
    <meta name="author" content="">
    <link rel="canonical" href="https:/blog/face-dataset-compression/">
    <link crossorigin="anonymous"
        href="/assets/css/stylesheet.min.2b833c6baa7a96407c2417c7a4049985b42c21cccc2472abf4603967eafd2273.css"
        integrity="sha256-K4M8a6p6lkB8JBfHpASZhbQsIczMJHKr9GA5Z&#43;r9InM=" rel="preload stylesheet" as="style">
    <script defer crossorigin="anonymous"
        src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js"
        integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
        onload="hljs.initHighlightingOnLoad();"></script>
    <link rel="icon" href="https://favicon.ico">
    <link rel="icon" type="image/png" sizes="16x16" href="https://favicon-16x16.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://favicon-32x32.png">
    <link rel="apple-touch-icon" href="https://apple-touch-icon.png">
    <link rel="mask-icon" href="https://safari-pinned-tab.svg">
    <meta name="theme-color" content="#2e2e33">
    <meta name="msapplication-TileColor" content="#2e2e33">
    <noscript>
        <style>
            #theme-toggle,
            .top-link {
                display: none;
            }
        </style>
        <style>
            @media (prefers-color-scheme: dark) {
                :root {
                    --theme: rgb(29, 30, 32);
                    --entry: rgb(46, 46, 51);
                    --primary: rgb(218, 218, 219);
                    --secondary: rgb(155, 156, 157);
                    --tertiary: rgb(65, 66, 68);
                    --content: rgb(196, 196, 197);
                    --hljs-bg: rgb(46, 46, 51);
                    --code-bg: rgb(55, 56, 62);
                    --border: rgb(51, 51, 51);
                }

                .list {
                    background: var(--theme);
                }

                .list:not(.dark)::-webkit-scrollbar-track {
                    background: 0 0;
                }

                .list:not(.dark)::-webkit-scrollbar-thumb {
                    border-color: var(--theme);
                }
            }
        </style>
    </noscript>
    <meta property="og:title" content="Face Dataset Compression using PCA" />
    <meta property="og:description" content="Principal Component Analysis for Image Dataset Compression" />
    <meta property="og:type" content="article" />
    <meta property="og:url" content="https:/blog/face-dataset-compression/" />
    <meta property="og:image" content="https:///blog/face-dataset-compression/cover.jpg" />
    <meta property="article:section" content="blog" />



    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:image" content="https:///blog/face-dataset-compression/cover.jpg" />
    <meta name="twitter:title" content="Face Dataset Compression using PCA" />
    <meta name="twitter:description" content="Principal Component Analysis for Image Dataset Compression" />


    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Blogs",
      "item": "https:/blog/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Face Dataset Compression using PCA",
      "item": "https:/blog/face-dataset-compression/"
    }
  ]
}
</script>
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Face Dataset Compression using PCA",
  "name": "Face Dataset Compression using PCA",
  "description": "Principal Component Analysis for Image Dataset Compression",
  "keywords": [
    "ML", "AI", "Python", "PCA", "Data Compression"
  ],
  "articleBody": "Introduction In this article, we will learn how PCA can be used to compress a real-life dataset. We will be working with Labelled Faces in the Wild (LFW), a large scale dataset consisting of 13233 human-face grayscale images, each having a dimension of 64x64. It means that the data for each face is 4096 dimensional (there are 64x64 = 4096 unique values to be stored for each face). We will reduce this dimension requirement, using PCA, to just a few hundred dimensions!\nPrincipal Component Analysis (PCA) Principal component analysis (PCA) is a technique for reducing the dimensionality of datasets, exploiting the fact that the images in these datasets have something in common. For instance, in a dataset consisting of face photographs, each photograph will have facial features like eyes, nose, mouth. Instead of encoding this information pixel by pixel, we could make a template of each type of these features and then just combine these templates to generate any face in the dataset. In this approach, each template will still be 64x64 = 4096 dimensional, but since we will be reusing these templates (basis functions) to generate each face in the dataset, the number of templates required will be small. PCA does exactly this. Let’s see how!\nDataset Let’s visualize some images from the dataset. You can see that each image has a complete face, and the facial features like eyes, nose, and lips are clearly visible in each image. Now that we have our dataset ready, let’s compress it.\nCompression PCA is a 4 step process. Starting with a dataset containing n dimensions (requiring n-axes to be represented):\n Step 1: Find a new set of basis functions (naxes) where some axes contribute to most of the variance in the dataset while others contribute very little. Step 2: Arrange these axes in the decreasing order of variance contribution. Step 3: Now, pick the top k axes to be used and drop the remaining n-k axes. Step 4: Now, project the dataset onto these k axes.  These steps are well explained in my previous article. After these 4 steps, the dataset will be compressed from n-dimensions to just k-dimensions (kn).\nStep 1 Finding a new set of basis functions (n-axes), where some axes contribute to most of the variance in the dataset while others contribute very little, is analogous to finding the templates that we will combine later to generate faces in the dataset. A total of 4096 templates, each 4096 dimensional, will be generated. Each face in the dataset can be represented as a linear combination of these templates.\nPlease note that the scalar constants (k1, k2, …, kn) will be unique for each face.\nStep 2 Now, some of these templates contribute significantly to facial reconstruction while others contribute very little. This level of contribution can be quantified as the percentage of variance that each template contributes to the dataset. So, in this step, we will arrange these templates in the decreasing order of variance contribution (most significant…least significant).\nStep 3 Now, we will keep the top k templates and drop the remaining. But, how many templates shall we keep? If we keep more templates, our reconstructed images will closely resemble the original images but we will need more storage to store the compressed data. If we keep too few templates, our reconstructed images will look very different from the original images.\nThe best solution is to fix the percentage of variance that we want to retain in the compressed dataset and use this to determine the value of k (number of templates to keep). If we do the math, we find that to retain 99% of the variance, we need only the top 577 templates. We will save these values in an array and drop the remaining templates.\nLet’s visualize some of these selected templates.\nPlease note that each of these templates looks somewhat like a face. These are called as Eigenfaces.\nStep 4 Now, we will construct a projection matrix to project the images from the original 4096 dimensions to just 577 dimensions. The projection matrix will have a shape (4096, 577), where the templates will be the columns of the matrix.\nBefore we go ahead and compress the images, let’s take a moment to understand what we really mean by compression. Recall that the faces can be generated by a linear combination of the selected templates. As each face is unique, every face in the dataset will require a different set of constants (k1, k2, …, kn) for the linear combination.\nLet’s start with an image from the dataset and compute the constants (k1, k2, …, kn), where n = 577. These constants along with the selected 577 templates can be plugged in the equation above to reconstruct the face. This means that we only need to compute and save these 577 constants for each image. Instead of doing this image by image, we can use matrices to compute these constants for each image in the dataset at the same time.\nRecall that there are 13233 images in the dataset. The matrix compressed_images contains the 577 constants for each image in the dataset. We can now say that we have compressed our images from 4096 dimensions to just 577 dimensions while retaining 99% of the information.\nCompression Ratio Let’s calculate how much we have compressed the dataset. Recall that there are 13233 images in the dataset and each image is 64x64 dimensional. So, the total number of unique values required to store the original dataset is13233 x 64 x 64 = 54,202,368 unique values.\nAfter compression, we store 577 constants for each image. So, the total number of unique values required to store the compressed dataset is13233 x 577 = 7,635,441 unique values. But, we also need to store the templates to reconstruct the images later. Therefore, we also need to store577 x 64 x 64 = 2,363,392 unique values for the templates. Therefore, the total number of unique values required to store the compressed dataset is7,635,441 + 2,363,392 = 9,998,883 unique values.\nWe can calculate the percentage compression as:\nReconstruct the Images The compressed images are just arrays of length 577 and can’t be visualized as such. We need to reconstruct it back to 4096 dimensions to view it as an array of shape (64x64). Recall that each template has a dimension of 64x64 and that each constant is a scalar value. We can use the equation below to reconstruct any face in the dataset.\nAgain, instead of doing this image by image, we can use matrices to reconstruct the whole dataset at once, with of course a loss of 1% variance.\nLet’s look at some reconstructed faces.\nWe can see that the reconstructed images have captured most of the relevant information about the faces and the unnecessary details have been ignored. This is an added advantage of data compression, it allows us to filter unnecessary details (and even noise) present in the data.\nThat’s all folks! If you made it till here, hats off to you! In this article, we learnt how PCA can be used to compress Labelled Faces in the Wild (LFW), a large scale dataset consisting of 13233 human-face images, each having a dimension of 64x64. We compressed this dataset by over 80% while retaining 99% of the information.\nColab Notebook View my Colab Notebook for a well commented code!\n",
  "wordCount" : "1229",
  "inLanguage": "en",
  "image":"https:///blog/face-dataset-compression/cover.jpg","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https:/blog/face-dataset-compression/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Rodrigo Soares",
    "logo": {
      "@type": "ImageObject",
      "url": "https://favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
    <script>
        if (localStorage.getItem("pref-theme") === "dark") {
            document.body.classList.add('dark');
        } else if (localStorage.getItem("pref-theme") === "light") {
            document.body.classList.remove('dark')
        } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
            document.body.classList.add('dark');
        }

    </script>

    <header class="header sticky-header">
        <nav class="nav">
            <div class="logo">
                <a href="https:" accesskey="h" title="Rodrigo Soares (Alt + H)">Rodrigo Soares</a>
                <span class="logo-switches">
                    <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                        <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                            stroke-linejoin="round">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                        </svg>
                        <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                            stroke-linejoin="round">
                            <circle cx="12" cy="12" r="5"></circle>
                            <line x1="12" y1="1" x2="12" y2="3"></line>
                            <line x1="12" y1="21" x2="12" y2="23"></line>
                            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                            <line x1="1" y1="12" x2="3" y2="12"></line>
                            <line x1="21" y1="12" x2="23" y2="12"></line>
                            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                        </svg>
                    </button>
                </span>
            </div>
            <ul id="menu">
                <li>
                    <a href="https:///" title="Home">
                        <span>Home</span>
                    </a>
                </li>
                <li>
                    <a href="https:///blog" title="Blog">
                        <span>Blog</span>
                    </a>
                </li>
                <li>
                    <a href="https:///projects" title="Projects">
                        <span>Projects</span>
                    </a>
                </li>
                <li>
                    <a href="https:///experience" title="Experience">
                        <span>Experience</span>
                    </a>
                </li>
                <li>
                    <a href="https:///search" title="Search (Alt &#43; /)" accesskey= />
                    <span>Search</span>
                    </a>
                </li>
            </ul>
        </nav>
    </header>
    <main class="main">

        <article class="post-single">
            <header class="post-header">
                <div class="breadcrumbs"><a href="https:">Home</a>&nbsp;»&nbsp;<a href="https:/blog/">Blogs</a></div>
                <h1 class="post-title">
                    Face Dataset Compression using PCA
                </h1>
                <div class="post-description">
                    Principal Component Analysis for Image Dataset Compression
                </div>
                <div class="post-meta">


                    Aug 2020

                </div>
            </header>
            <figure class="entry-cover"><img loading="lazy" src="https:///blog/face-dataset-compression/cover.jpg"
                    alt="">

            </figure>
            <div class="toc">
                <details>
                    <summary accesskey="c" title="(Alt + C)">
                        <span class="details">‎ Table of Contents</span>
                    </summary>

                    <div class="inner">
                        <ul>
                            <li>
                                <a href="#introduction" aria-label="Introduction">Introduction</a>
                            </li>
                            <li>
                                <a href="#principal-component-analysis-pca"
                                    aria-label="Principal Component Analysis (PCA)">Principal Component Analysis
                                    (PCA)</a>
                            </li>
                            <li>
                                <a href="#dataset" aria-label="Dataset">Dataset</a>
                            </li>
                            <li>
                                <a href="#compression" aria-label="Compression">Compression</a>
                                <ul>

                                    <li>
                                        <a href="#step-1" aria-label="Step 1">Step 1</a>
                                    </li>
                                    <li>
                                        <a href="#step-2" aria-label="Step 2">Step 2</a>
                                    </li>
                                    <li>
                                        <a href="#step-3" aria-label="Step 3">Step 3</a>
                                    </li>
                                    <li>
                                        <a href="#step-4" aria-label="Step 4">Step 4</a>
                                    </li>
                                </ul>
                            </li>
                            <li>
                                <a href="#compression-ratio" aria-label="Compression Ratio">Compression Ratio</a>
                            </li>
                            <li>
                                <a href="#reconstruct-the-images" aria-label="Reconstruct the Images">Reconstruct the
                                    Images</a>
                            </li>
                            <li>
                                <a href="#thats-all-folks" aria-label="That’s all folks!">That’s all folks!</a>
                            </li>
                            <li>
                                <a href="#colab-notebook" aria-label="Colab Notebook">Colab Notebook</a>
                            </li>
                        </ul>
                    </div>
                </details>
            </div>

            <div class="post-content">
                <h1 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a>
                </h1>
                <p>In this article, we will learn how PCA can be used to compress a real-life dataset. We will be
                    working with <strong>Labelled Faces in the Wild (LFW),</strong> a large scale dataset consisting
                    of <strong>13233</strong> human-face grayscale images, each having a dimension
                    of <strong>64x64</strong>. It means that the data for each face is 4096 dimensional (there are 64x64
                    = 4096 unique values to be stored for each face). We will reduce this dimension requirement, using
                    PCA, to just a few hundred dimensions!</p>
                <h1 id="principal-component-analysis-pca">Principal Component Analysis (PCA)<a hidden class="anchor"
                        aria-hidden="true" href="#principal-component-analysis-pca">#</a></h1>
                <p>Principal component analysis (PCA) is a technique for reducing the dimensionality of datasets,
                    exploiting the fact that the images in these datasets have something in common. For instance, in a
                    dataset consisting of face photographs, each photograph will have facial features like eyes, nose,
                    mouth. Instead of encoding this information pixel by pixel, we could make a template of each type of
                    these features and then just combine these templates to generate any face in the dataset. In this
                    approach, each template will still be 64x64 = 4096 dimensional, but since we will be reusing these
                    templates (basis functions) to generate each face in the dataset, the number of templates required
                    will be small. PCA does exactly this. Let’s see how!</p>
                <h1 id="dataset">Dataset<a hidden class="anchor" aria-hidden="true" href="#dataset">#</a></h1>
                <p>Let’s visualize some images from the dataset. You can see that each image has a complete face, and
                    the facial features like eyes, nose, and lips are clearly visible in each image. Now that we have
                    our dataset ready, let’s compress it.</p>
                <p><img loading="lazy" src="/blog/face-dataset-compression/img1.jpg" alt="" />
                </p>
                <h1 id="compression">Compression<a hidden class="anchor" aria-hidden="true" href="#compression">#</a>
                </h1>
                <p><strong>PCA is a 4 step process.</strong> Starting with a dataset containing <em>n</em> dimensions
                    (requiring <em>n</em>-axes to be represented):</p>
                <ul>
                    <li><strong>Step 1</strong>: Find a new set of basis functions (<em>n</em>axes) where some axes
                        contribute to most of the variance in the dataset while others contribute very little.</li>
                    <li><strong>Step 2</strong>: Arrange these axes in the decreasing order of variance contribution.
                    </li>
                    <li><strong>Step 3</strong>: Now, pick the top <em>k</em> axes to be used and drop the
                        remaining <em>n-k</em> axes.</li>
                    <li><strong>Step 4</strong>: Now, project the dataset onto these <em>k</em> axes.</li>
                </ul>
                <p>These steps are well explained in my previous article. After these 4 steps, the dataset will be
                    compressed from <em>n</em>-dimensions to just <em>k</em>-dimensions (<em>k</em>&lt;<em>n</em>).</p>
                <h2 id="step-1">Step 1<a hidden class="anchor" aria-hidden="true" href="#step-1">#</a></h2>
                <p>Finding a new set of basis functions (<em>n</em>-axes), where some axes contribute to most of the
                    variance in the dataset while others contribute very little, is analogous to finding the templates
                    that we will combine later to generate faces in the dataset. A total of 4096 templates, each 4096
                    dimensional, will be generated. Each face in the dataset can be represented as a linear combination
                    of these templates.</p>
                <p><img loading="lazy" src="/blog/face-dataset-compression/img2.jpg" alt="" />
                </p>
                <p>Please note that the scalar constants (k1, k2, …, kn) will be unique for each face.</p>
                <h2 id="step-2">Step 2<a hidden class="anchor" aria-hidden="true" href="#step-2">#</a></h2>
                <p>Now, some of these templates contribute significantly to facial reconstruction while others
                    contribute very little. This level of contribution can be quantified as the percentage of variance
                    that each template contributes to the dataset. So, in this step, we will arrange these templates in
                    the decreasing order of variance contribution (most significant…least significant).</p>
                <h2 id="step-3">Step 3<a hidden class="anchor" aria-hidden="true" href="#step-3">#</a></h2>
                <p>Now, we will keep the top <em>k</em> templates and drop the remaining. But, how many templates shall
                    we keep? If we keep more templates, our reconstructed images will closely resemble the original
                    images but we will need more storage to store the compressed data. If we keep too few templates, our
                    reconstructed images will look very different from the original images.</p>
                <p>The best solution is to fix the percentage of variance that we want to retain in the compressed
                    dataset and use this to determine the value of <em>k</em> (number of templates to keep). If we do
                    the math, we find that to retain <strong>99%</strong> of the variance, we need only the
                    top <strong>577</strong> templates. We will save these values in an array and drop the remaining
                    templates.</p>
                <p>Let’s visualize some of these selected templates.</p>
                <p><img loading="lazy" src="/blog/face-dataset-compression/img3.jpg" alt="" />
                </p>
                <p>Please note that each of these templates looks somewhat like a face. These are called as Eigenfaces.
                </p>
                <h2 id="step-4">Step 4<a hidden class="anchor" aria-hidden="true" href="#step-4">#</a></h2>
                <p>Now, we will construct a projection matrix to project the images from the original 4096 dimensions to
                    just 577 dimensions. The projection matrix will have a shape <strong>(4096, 577)</strong>, where the
                    templates will be the columns of the matrix.</p>
                <p>Before we go ahead and compress the images, let’s take a moment to understand what we really mean by
                    compression. Recall that the faces can be generated by a linear combination of the selected
                    templates. As each face is unique, every face in the dataset will require a different set of
                    constants (k1, k2, …, kn) for the linear combination.</p>
                <p><img loading="lazy" src="/blog/face-dataset-compression/img2.jpg" alt="" />
                </p>
                <p>Let’s start with an image from the dataset and compute the constants (k1, k2, …, kn), where n = 577.
                    These constants along with the selected 577 templates can be plugged in the equation above to
                    reconstruct the face. This means that we only need to compute and save these 577 constants for each
                    image. Instead of doing this image by image, we can use matrices to compute these constants for each
                    image in the dataset at the same time.</p>
                <p><img loading="lazy" src="/blog/face-dataset-compression/img4.jpg" alt="" />
                </p>
                <p>Recall that there are 13233 images in the dataset. The matrix compressed_images contains the 577
                    constants for each image in the dataset. We can now say that we have compressed our images from 4096
                    dimensions to just 577 dimensions while retaining 99% of the information.</p>
                <h1 id="compression-ratio">Compression Ratio<a hidden class="anchor" aria-hidden="true"
                        href="#compression-ratio">#</a></h1>
                <p>Let’s calculate how much we have compressed the dataset. Recall that there are 13233 images in the
                    dataset and each image is 64x64 dimensional. So, the total number of unique values required to store
                    the original dataset is13233 x 64 x 64 = <strong>54,202,368 unique values</strong>.</p>
                <p>After compression, we store 577 constants for each image. So, the total number of unique values
                    required to store the compressed dataset is13233 x 577 = 7,635,441 unique values. But, we also need
                    to store the templates to reconstruct the images later. Therefore, we also need to store577 x 64 x
                    64 = 2,363,392 unique values for the templates. Therefore, the total number of unique values
                    required to store the compressed dataset is7,635,441 + 2,363,392 = <strong>9,998,883 unique
                        values</strong>.</p>
                <p>We can calculate the percentage compression as:</p>
                <p><img loading="lazy" src="/blog/face-dataset-compression/img5.jpg" alt="" />
                </p>
                <h1 id="reconstruct-the-images">Reconstruct the Images<a hidden class="anchor" aria-hidden="true"
                        href="#reconstruct-the-images">#</a></h1>
                <p>The compressed images are just arrays of length 577 and can’t be visualized as such. We need to
                    reconstruct it back to 4096 dimensions to view it as an array of shape (64x64). Recall that each
                    template has a dimension of 64x64 and that each constant is a scalar value. We can use the equation
                    below to reconstruct any face in the dataset.</p>
                <p><img loading="lazy" src="/blog/face-dataset-compression/img2.jpg" alt="" />
                </p>
                <p>Again, instead of doing this image by image, we can use matrices to reconstruct the whole dataset at
                    once, with of course a loss of 1% variance.</p>
                <p><img loading="lazy" src="/blog/face-dataset-compression/img6.jpg" alt="" />
                </p>
                <p>Let’s look at some reconstructed faces.</p>
                <p><img loading="lazy" src="/blog/face-dataset-compression/img7.jpg" alt="" />
                </p>
                <p>We can see that the reconstructed images have captured most of the relevant information about the
                    faces and the unnecessary details have been ignored. This is an added advantage of data compression,
                    it allows us to filter unnecessary details (and even noise) present in the data.</p>
                <h1 id="thats-all-folks">That’s all folks!<a hidden class="anchor" aria-hidden="true"
                        href="#thats-all-folks">#</a></h1>
                <p>If you made it till here, hats off to you! In this article, we learnt how PCA can be used to
                    compress <strong>Labelled Faces in the Wild (LFW),</strong> a large scale dataset consisting of
                    13233 human-face images, each having a dimension of <strong>64x64</strong>. We compressed this
                    dataset by over 80% while retaining 99% of the information.</p>
                <h1 id="colab-notebook">Colab Notebook<a hidden class="anchor" aria-hidden="true"
                        href="#colab-notebook">#</a></h1>
                <p>View my <a href="https://colab.research.google.com/drive/1QZYqjLm_rLxkgR6COMjjBicHSLMwKxF-">Colab
                        Notebook</a> for a well commented code!</p>


            </div>

            <footer class="post-footer">
                <ul class="post-tags">
                    <li><a href="https:/tags/ml/">ML</a></li>
                    <li><a href="https:/tags/ai/">AI</a></li>
                    <li><a href="https:/tags/python/">Python</a></li>
                    <li><a href="https:/tags/pca/">PCA</a></li>
                    <li><a href="https:/tags/data-compression/">Data Compression</a></li>
                </ul>
            </footer>
        </article>
    </main>

    <footer class="footer">
        <span>&copy; 2022 <a href="https:">Rodrigo Soares</a></span>
    </footer>
    <a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z" />
        </svg>
    </a>

    <script>
        let menu = document.getElementById('menu')
        if (menu) {
            menu.scrollLeft = localStorage.getItem("menu-scroll-position");
            menu.onscroll = function () {
                localStorage.setItem("menu-scroll-position", menu.scrollLeft);
            }
        }

        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener("click", function (e) {
                e.preventDefault();
                var id = this.getAttribute("href").substr(1);
                if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                    document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                        behavior: "smooth"
                    });
                } else {
                    document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
                }
                if (id === "top") {
                    history.replaceState(null, null, " ");
                } else {
                    history.pushState(null, null, `#${id}`);
                }
            });
        });

    </script>
    <script>
        var mybutton = document.getElementById("top-link");
        window.onscroll = function () {
            if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
                mybutton.style.visibility = "visible";
                mybutton.style.opacity = "1";
            } else {
                mybutton.style.visibility = "hidden";
                mybutton.style.opacity = "0";
            }
        };

    </script>
    <script>
        document.getElementById("theme-toggle").addEventListener("click", () => {
            if (document.body.className.includes("dark")) {
                document.body.classList.remove('dark');
                localStorage.setItem("pref-theme", 'light');
            } else {
                document.body.classList.add('dark');
                localStorage.setItem("pref-theme", 'dark');
            }
        })

    </script>
    <script>
        document.querySelectorAll('pre > code').forEach((codeblock) => {
            const container = codeblock.parentNode.parentNode;

            const copybutton = document.createElement('button');
            copybutton.classList.add('copy-code');
            copybutton.innerHTML = 'copy';

            function copyingDone() {
                copybutton.innerHTML = 'copied!';
                setTimeout(() => {
                    copybutton.innerHTML = 'copy';
                }, 2000);
            }

            copybutton.addEventListener('click', (cb) => {
                if ('clipboard' in navigator) {
                    navigator.clipboard.writeText(codeblock.textContent);
                    copyingDone();
                    return;
                }

                const range = document.createRange();
                range.selectNodeContents(codeblock);
                const selection = window.getSelection();
                selection.removeAllRanges();
                selection.addRange(range);
                try {
                    document.execCommand('copy');
                    copyingDone();
                } catch (e) { };
                selection.removeRange(range);
            });

            if (container.classList.contains("highlight")) {
                container.appendChild(copybutton);
            } else if (container.parentNode.firstChild == container) {

            } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {

                codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
            } else {

                codeblock.parentNode.appendChild(copybutton);
            }
        });
    </script>
</body>

</html>